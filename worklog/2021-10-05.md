# 2021-10-05 Work Log

## 멘토링

### QA
1. huggingface 모델을 custom하고 싶을 때 방법 ex) embedding layer 추가 등
    - layer customizing 적용 완료 & 해결
2. huggingface에서 pytorch.dataloder의 sampler를 적용하고 싶은데 방법을 잘 모르겠다. huggingface의 dataloder를 custom하는 방법도 궁금합니다.
    - trainer class 상속받은 custom trainer class에서 dataloader function overiding, sampler 적용 해결.
3. 현직에 계시는 분에게 언뜻 듣기로 실제 서비스 배포할때는 앙상블 기법을 잘쓰지 않는다고 하는데, 맞는지 궁금합니다. 그렇다면 특별한 이유가 있는지도 알고 싶습니다.
    - 최적화된 모델 성능이 threshold 수렴 가정 시, 앙상블과 싱글 모델 성능 차이가 크지 않다.
    - product 측면에서, real time(online-learning)과 edge device inference time을 모두 고려해야 하므로 앙상블을 deploy하기엔 무리가 있다.
    - Network pruning 등의 경량화 모델을 사용하는 것이 최근 ML trend.

### 추가 내용
- pytorch는 research에, tensorflow는 production에 주로 사용된다.
- single gpu는 무리기에 요즘엔 거의 multi gpu, machine으로 분산처리하여 성능 및 속도 향상한다.
- 앙상블 모델 선택에 정해진 공식은 없고, 실험을 통해 성능 향상이 뚜렷한 모델들을 골라 앙상블 진행!

## 대회 진행상황
- 진영님(HPO)
- final dataset : 혜원님(일본어 back-translation) + 재욱님(switch-subject_token-object_token) + 재현님(AEDA) (예정)
- 범준님(Loss, optimizer, LRscheduler 실험)
- 연걸님(일본어 모델 실험)
- 성민님(imbalanced data generation 실험)


## 앙상블 계획
- model
    - klue/roberta-large
        - 혜원 - sentence
        - 범준 - puct type
    - klue/bert-base
        - 재욱 - puct type
        - 진영 - swap
    - xlm/roberta-large
        - 재현 - puct type
        - 성민 - swap
    - koelectra-base
        - 연걸 - puct type
    
    7_C_5 = 21
    
- data fix : 재현님 AEDA 적용 ver (원본 + 일본어BT + swap)
    
    [Slack](https://aitech2.slack.com/files/U029F2PUHBM/F02GP7KPT3M/other_falimy_criterion_train.csv)
    
- entity
    - puct type : roberta에 좋음
    - sentence
    - swap
- epoch : 5
- batch size
    - large 64
- max_length = 128
