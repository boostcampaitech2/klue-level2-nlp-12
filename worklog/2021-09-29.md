# 2021.09.28 회의록
## 1. BERT Review

BERT 3줄요약

- Pre-training -> Fine tuning
- Unlabeled Sentences (Masked LM, Next Sentence Prediction)
- Bidirectional

## 2. KLUE EDA

- 한글말고도 여러 언어가 들어가 있다.

- 영어, 일본어, 한자 ... 등

- 특수문자는 규칙을 정해서 제거

- 토론 게시판을 꼼꼼하게 읽자

- no_relation을 어떻게 처리할까?

  - 데이터를 직접 보며 처리
  - model input에서 처리

  

- [지난 기수 1등팀 링크](https://github.com/bcaitech1/p2-klue-LeeHyeonKyu/blob/main/etc/wrap_up_report.pdf)

- **Model을 fix하고 2팀 (전처리 vs Aug) 나눠서 작업해보자**

  - Preprocessing team
    - 연걸님
    - 재욱님
    - 진영님
  - Augmentation team
    - 범준님
    - 혜원님
    - 성민님
    - 재현님

## 3. 부가정보

- 모각공 slack에 글 올리고 스티커로 참여 표시하기.

## 4. 내일

- RoBERTa 논문 리뷰